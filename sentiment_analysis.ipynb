{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7ff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Library paths arranged successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 19:43:14.940379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-18 19:43:14.940471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-18 19:43:15.011949: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-18 19:43:15.182644: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-18 19:43:16.618613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.15.0\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 19:43:18.612951: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 19:43:19.100256: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-18 19:43:19.101084: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Detected and memory setting done: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import site\n",
    "\n",
    "try:\n",
    "    site_packages = site.getsitepackages()[0]\n",
    "    nvidia_path = os.path.join(site_packages, 'nvidia')\n",
    "    \n",
    "    cudnn_path = os.path.join(nvidia_path, 'cudnn', 'lib')\n",
    "    cuda_path = os.path.join(nvidia_path, 'cuda_runtime', 'lib')\n",
    "    \n",
    "    old_ld = os.environ.get('LD_LIBRARY_PATH', '')\n",
    "    os.environ['LD_LIBRARY_PATH'] = f\"{cudnn_path}:{cuda_path}:{old_ld}\"\n",
    "    \n",
    "    os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'\n",
    "    \n",
    "    print(\"NVIDIA Library paths arranged successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Path warning: {e}\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPUs: {gpus}\")\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# GPU Bellek Ayarı (Memory Growth)\n",
    "# Bu kısım importlardan hemen sonra çalışmalı\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Detected and memory setting done: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f1e8c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5c5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8407fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(dataframe):\n",
    "    \"\"\"\n",
    "    Checks the overall structure and key metrics of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame to inspect.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints shape, data types, head, tail, missing values, and quantiles.\n",
    "    \"\"\"\n",
    "    print(\"##################### Shape #####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"##################### Types #####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"##################### Head #####################\")\n",
    "    print(dataframe.head(5))\n",
    "    print(\"##################### Tail #####################\")\n",
    "    print(dataframe.tail(5))\n",
    "    print(\"##################### NA #####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print('##################### Unique Values #####################')\n",
    "    print(dataframe.nunique())\n",
    "    print(\"##################### Duplicates #####################\")\n",
    "    print(dataframe.duplicated().sum())\n",
    "    print(\"##################### Quantiles #####################\")\n",
    "    # Uncomment below to include quantile information\n",
    "    #print(dataframe[[col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]].quantile([0, 0.05, 0.50, 0.75, 0.95, 0.99, 1]).T)\n",
    "    print(dataframe.describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70be243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    df_train = pd.read_csv(\"data/train.csv\", encoding=\"UTF-8\", engine=\"python\", encoding_errors=\"replace\")#replaces damaged bytes with \"\\ufffd\"\n",
    "    return df_train\n",
    "\n",
    "def load_test():\n",
    "    df_test = pd.read_csv(\"data/test.csv\", encoding=\"UTF-8\", engine=\"python\", encoding_errors=\"replace\")\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e15f244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_train()\n",
    "df_test = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fda9fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(440679, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0  ürünü hepsiburadadan alalı 3 hafta oldu. orjin...  Positive\n",
      "1  ürünlerden çok memnunum, kesinlikle herkese ta...  Positive\n",
      "2      hızlı kargo, temiz alışveriş.teşekkür ederim.  Positive\n",
      "3               Çünkü aranan tapınak bu bölgededir .      Notr\n",
      "4  bu telefonu başlıca alma nedenlerim ise elimde...  Positive\n",
      "##################### Tail #####################\n",
      "                                                     text     label\n",
      "440674  Ayrıca burç yorumları ve çapraz bulmaca da der...      Notr\n",
      "440675  günümüz de ssd olmazsa olmaz bir donanım artık...  Positive\n",
      "440676  kullandım ve çok memnun kaldım. ocak başında d...  Positive\n",
      "440677                Adını Lenkeran şehrinden almıştır .      Notr\n",
      "440678  Bu dergilerde sosyalist teori ve siyasete iliş...      Notr\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     438997\n",
      "label         3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "1616\n",
      "##################### Quantiles #####################\n",
      "        count  unique       top    freq\n",
      "text   440679  438997    #NAME?    1062\n",
      "label  440679       3  Positive  235949\n"
     ]
    }
   ],
   "source": [
    "check_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b783f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(48965, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0      Kral akbaba dikkat çekici renklere sahiptir .      Notr\n",
      "1   ısrarla korkutmayı başarıyor. sanki korku çok...  Positive\n",
      "2  Neşe ve Üzüntü köprünün kırılmaya başlamasıyla...      Notr\n",
      "3  i phone 5 ten sonra gene 4'' ekranı tercih ett...  Positive\n",
      "4    Beşinci sezonda diziye yeni oyuncular katıldı .      Notr\n",
      "##################### Tail #####################\n",
      "                                                    text     label\n",
      "48960  Fransa bayrağı diğer kırmızı zeminden beyaz bi...      Notr\n",
      "48961  Yine aynı yıl türkü dalında Murat Çobanoğlu il...      Notr\n",
      "48962                           Kurgunu skiyim oç evladı  Negative\n",
      "48963  Şarkı daha sonrasında Damian Marley tarafından...      Notr\n",
      "48964  berrak bir ürün ancak kendi orijinal spigen ly...  Negative\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     48830\n",
      "label        3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "131\n",
      "##################### Quantiles #####################\n",
      "       count unique       top   freq\n",
      "text   48965  48830    #NAME?    119\n",
      "label  48965      3  Positive  26217\n"
     ]
    }
   ],
   "source": [
    "check_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12376162",
   "metadata": {},
   "source": [
    "- damaged rows filtering, these can be considered to be dropped\n",
    "- also other (#NAME?) damage can be seen during data read, these rows will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5a1f10f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total damaged rows in train: 7\n",
      "                                                     text     label\n",
      "31512   - su akıtmıyor: adamlar kullanam klavuzuna yaz...  Positive\n",
      "55634   -kargocu arkadaşlar ürünü bir bayan olarak taş...  Positive\n",
      "64093   - kullanım tarifindeki 'hazneye sıcak su koyun...  Positive\n",
      "102817  -kamerasına laf edilmiş. çıktığı dönemin en iy...  Positive\n",
      "332479  - karşı taraf sesimden çok memnun ama ben karş...  Positive\n",
      "Total damaged rows in test: 0\n",
      "Empty DataFrame\n",
      "Columns: [text, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "damaged_rows_train = df_train[df_train[\"text\"].str.contains(\"\\ufffd\", na=False)]\n",
    "damaged_rows_test = df_test[df_test[\"text\"].str.contains(\"\\ufffd\", na=False)]\n",
    "\n",
    "print(f\"Total damaged rows in train: {len(damaged_rows_train)}\")\n",
    "\n",
    "print(damaged_rows_train.head())\n",
    "\n",
    "print(f\"Total damaged rows in test: {len(damaged_rows_test)}\")\n",
    "\n",
    "print(damaged_rows_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1031daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(index=damaged_rows_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7ee79b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['text'] != \"#NAME?\"]\n",
    "df_test = df_test[df_test['text'] != \"#NAME?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "548c2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    df_train[col] = df_train[col].str.lower() # Normalizing Case Folding\n",
    "    df_train[col] = df_train[col].str.replace(r'[^\\w\\s]', '', regex=True) # Punctuations\n",
    "    df_train[col] = df_train[col].str.replace(r'\\d+', '', regex=True) # Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2f6e791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_test.columns:\n",
    "    df_test[col] = df_test[col].str.lower() # Normalizing Case Folding\n",
    "    df_test[col] = df_test[col].str.replace(r'[^\\w\\s]', '', regex=True) # Punctuations\n",
    "    df_test[col] = df_test[col].str.replace(r'\\d+', '', regex=True) # Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cfd5647e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(439610, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0  ürünü hepsiburadadan alalı  hafta oldu orjinal...  positive\n",
      "1  ürünlerden çok memnunum kesinlikle herkese tav...  positive\n",
      "2         hızlı kargo temiz alışverişteşekkür ederim  positive\n",
      "3                çünkü aranan tapınak bu bölgededir       notr\n",
      "4  bu telefonu başlıca alma nedenlerim ise elimde...  positive\n",
      "##################### Tail #####################\n",
      "                                                     text     label\n",
      "440674  ayrıca burç yorumları ve çapraz bulmaca da der...      notr\n",
      "440675  günümüz de ssd olmazsa olmaz bir donanım artık...  positive\n",
      "440676  kullandım ve çok memnun kaldım ocak başında da...  positive\n",
      "440677                 adını lenkeran şehrinden almıştır       notr\n",
      "440678  bu dergilerde sosyalist teori ve siyasete iliş...      notr\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     436516\n",
      "label         3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "2999\n",
      "##################### Quantiles #####################\n",
      "        count  unique       top    freq\n",
      "text   439610  436516                58\n",
      "label  439610       3  positive  234994\n"
     ]
    }
   ],
   "source": [
    "check_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "836ee396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(48846, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0       kral akbaba dikkat çekici renklere sahiptir       notr\n",
      "1   ısrarla korkutmayı başarıyor sanki korku çok ...  positive\n",
      "2  neşe ve üzüntü köprünün kırılmaya başlamasıyla...      notr\n",
      "3  i phone  ten sonra gene  ekranı tercih ettim t...  positive\n",
      "4     beşinci sezonda diziye yeni oyuncular katıldı       notr\n",
      "##################### Tail #####################\n",
      "                                                    text     label\n",
      "48960  fransa bayrağı diğer kırmızı zeminden beyaz bi...      notr\n",
      "48961  yine aynı yıl türkü dalında murat çobanoğlu il...      notr\n",
      "48962                           kurgunu skiyim oç evladı  negative\n",
      "48963  şarkı daha sonrasında damian marley tarafından...      notr\n",
      "48964  berrak bir ürün ancak kendi orijinal spigen ly...  negative\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     48768\n",
      "label        3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "70\n",
      "##################### Quantiles #####################\n",
      "       count unique       top   freq\n",
      "text   48846  48768                9\n",
      "label  48846      3  positive  26110\n"
     ]
    }
   ],
   "source": [
    "check_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "602703ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(inplace=True)\n",
    "df_test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "432d409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(436611, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0  ürünü hepsiburadadan alalı  hafta oldu orjinal...  positive\n",
      "1  ürünlerden çok memnunum kesinlikle herkese tav...  positive\n",
      "2         hızlı kargo temiz alışverişteşekkür ederim  positive\n",
      "3                çünkü aranan tapınak bu bölgededir       notr\n",
      "4  bu telefonu başlıca alma nedenlerim ise elimde...  positive\n",
      "##################### Tail #####################\n",
      "                                                     text     label\n",
      "440674  ayrıca burç yorumları ve çapraz bulmaca da der...      notr\n",
      "440675  günümüz de ssd olmazsa olmaz bir donanım artık...  positive\n",
      "440676  kullandım ve çok memnun kaldım ocak başında da...  positive\n",
      "440677                 adını lenkeran şehrinden almıştır       notr\n",
      "440678  bu dergilerde sosyalist teori ve siyasete iliş...      notr\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     436516\n",
      "label         3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "0\n",
      "##################### Quantiles #####################\n",
      "        count  unique       top    freq\n",
      "text   436611  436516                 3\n",
      "label  436611       3  positive  232626\n",
      "##################### Shape #####################\n",
      "(48776, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0       kral akbaba dikkat çekici renklere sahiptir       notr\n",
      "1   ısrarla korkutmayı başarıyor sanki korku çok ...  positive\n",
      "2  neşe ve üzüntü köprünün kırılmaya başlamasıyla...      notr\n",
      "3  i phone  ten sonra gene  ekranı tercih ettim t...  positive\n",
      "4     beşinci sezonda diziye yeni oyuncular katıldı       notr\n",
      "##################### Tail #####################\n",
      "                                                    text     label\n",
      "48960  fransa bayrağı diğer kırmızı zeminden beyaz bi...      notr\n",
      "48961  yine aynı yıl türkü dalında murat çobanoğlu il...      notr\n",
      "48962                           kurgunu skiyim oç evladı  negative\n",
      "48963  şarkı daha sonrasında damian marley tarafından...      notr\n",
      "48964  berrak bir ürün ancak kendi orijinal spigen ly...  negative\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     48768\n",
      "label        3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "0\n",
      "##################### Quantiles #####################\n",
      "       count unique          top   freq\n",
      "text   48776  48768  teşekkürler      2\n",
      "label  48776      3     positive  26053\n"
     ]
    }
   ],
   "source": [
    "check_df(df_train)\n",
    "check_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c43678",
   "metadata": {},
   "source": [
    "**\"kullanam klavuzu\", encoding=\"hırt\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec8354",
   "metadata": {},
   "source": [
    "**TASK**\n",
    "\n",
    "4 different models ([TF-IDF with Multinomial Naive Bayes and Binary Naive Bayes] + [ANN with Word2Vec and FastText]) will be trained and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff79b7",
   "metadata": {},
   "source": [
    "**ROADMAP**\n",
    "\n",
    "Preprocessing steps will be applied on data according to models they will be fed to.\n",
    "\n",
    "***For Bayesian Model:***\n",
    "- Lowecase transformation\n",
    "- Special characters cleaning (Punctuations etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "499d0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df_on_y_axis(df_1, df_2):\n",
    "    \"\"\"\n",
    "    Concatenates two DataFrames along the Y-axis (rows).\n",
    "\n",
    "    Args:\n",
    "        df_1 (pd.DataFrame): First DataFrame.\n",
    "        df_2 (pd.DataFrame): Second DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.concat([df_1, df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "61a587fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test = concat_df_on_y_axis(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f1998d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(485387, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0  ürünü hepsiburadadan alalı  hafta oldu orjinal...  positive\n",
      "1  ürünlerden çok memnunum kesinlikle herkese tav...  positive\n",
      "2         hızlı kargo temiz alışverişteşekkür ederim  positive\n",
      "3                çünkü aranan tapınak bu bölgededir       notr\n",
      "4  bu telefonu başlıca alma nedenlerim ise elimde...  positive\n",
      "##################### Tail #####################\n",
      "                                                    text     label\n",
      "48960  fransa bayrağı diğer kırmızı zeminden beyaz bi...      notr\n",
      "48961  yine aynı yıl türkü dalında murat çobanoğlu il...      notr\n",
      "48962                           kurgunu skiyim oç evladı  negative\n",
      "48963  şarkı daha sonrasında damian marley tarafından...      notr\n",
      "48964  berrak bir ürün ancak kendi orijinal spigen ly...  negative\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     484755\n",
      "label         3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "515\n",
      "##################### Quantiles #####################\n",
      "        count  unique       top    freq\n",
      "text   485387  484755                 5\n",
      "label  485387       3  positive  258679\n"
     ]
    }
   ],
   "source": [
    "check_df(df_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c816f75",
   "metadata": {},
   "source": [
    "**OBSERVATIONS**\n",
    "- df_train has 0 duplicates, duplicates dropped.\n",
    "- df_test has 0 duplicates, duplicates dropped.\n",
    "- df_train_test has 515 duplicates.\n",
    "- **Data Leakage observed**\n",
    "- Set of {df_train INTERSECT df_test} has to be removed from df_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0e5f0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = set(df_test['text'])\n",
    "df_train = df_train[~df_train['text'].isin(test_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "650dff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test = concat_df_on_y_axis(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a35c1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(484835, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0  ürünü hepsiburadadan alalı  hafta oldu orjinal...  positive\n",
      "1  ürünlerden çok memnunum kesinlikle herkese tav...  positive\n",
      "2         hızlı kargo temiz alışverişteşekkür ederim  positive\n",
      "3                çünkü aranan tapınak bu bölgededir       notr\n",
      "4  bu telefonu başlıca alma nedenlerim ise elimde...  positive\n",
      "##################### Tail #####################\n",
      "                                                    text     label\n",
      "48960  fransa bayrağı diğer kırmızı zeminden beyaz bi...      notr\n",
      "48961  yine aynı yıl türkü dalında murat çobanoğlu il...      notr\n",
      "48962                           kurgunu skiyim oç evladı  negative\n",
      "48963  şarkı daha sonrasında damian marley tarafından...      notr\n",
      "48964  berrak bir ürün ancak kendi orijinal spigen ly...  negative\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     484755\n",
      "label         3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "0\n",
      "##################### Quantiles #####################\n",
      "        count  unique       top    freq\n",
      "text   484835  484755       mrb       3\n",
      "label  484835       3  positive  258277\n"
     ]
    }
   ],
   "source": [
    "check_df(df_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c65be0",
   "metadata": {},
   "source": [
    "**Data Leakage problem solved**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca3654",
   "metadata": {},
   "source": [
    "## Naive Bayes Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34564fd0",
   "metadata": {},
   "source": [
    "**STOPWORDS REMOVAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bafd1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0fe655ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ghost/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "sw = stopwords.words('turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b2adad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test_sw_removed = df_train_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "670c917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test_sw_removed['text'] = df_train_test_sw_removed['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6920c",
   "metadata": {},
   "source": [
    "**STEMMING**\n",
    "- Stemming is easy and will produce enough efficiency with bayesian models\n",
    "- Lemmatization can be alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cf3417d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TurkishStemmer import TurkishStemmer\n",
    "stemmer = TurkishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "78b1e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test_sw_removed['text'] = df_train_test_sw_removed['text'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d3b860ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(484835, 2)\n",
      "##################### Types #####################\n",
      "text     object\n",
      "label    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                                                text     label\n",
      "0  ürün hepsiburada alal haf olt orjinal eksiks ş...  positive\n",
      "1  ürün memnu kesinlik herk tavsi eder ayrı hepsi...  positive\n",
      "2              hızl kargo tem alışverişteşekkür eder  positive\n",
      "3                               aranan tapınak bölge      notr\n",
      "4  telefon başl al neden elim samsung j ar yeters...  positive\n",
      "##################### Tail #####################\n",
      "                                                    text     label\n",
      "48960  fran bayrak diğer kır zem beyaz bir çerçev ayr...      notr\n",
      "48961  yin aynı yıl türk dal murat çobanok birlik bir...      notr\n",
      "48962                                  kurg skiy oç evla  negative\n",
      "48963         şark sonra damian marley taraf seslendiril      notr\n",
      "48964  berrak bir ürün ancak kent orijinal spigen lyq...  negative\n",
      "##################### NA #####################\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "##################### Unique Values #####################\n",
      "text     480838\n",
      "label         3\n",
      "dtype: int64\n",
      "##################### Duplicates #####################\n",
      "3833\n",
      "##################### Quantiles #####################\n",
      "        count  unique       top    freq\n",
      "text   484835  480838       iyi      31\n",
      "label  484835       3  positive  258277\n"
     ]
    }
   ],
   "source": [
    "check_df(df_train_test_sw_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "69a1f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(df_train)\n",
    "\n",
    "df_train_sw_removed_stemmed = df_train_test_sw_removed.iloc[:len_train].copy()\n",
    "\n",
    "df_test_sw_removed_stemmed = df_train_test_sw_removed.iloc[len_train:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d88a0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_sw_removed_stemmed['text']\n",
    "y_train = df_train_sw_removed_stemmed['label']\n",
    "X_test = df_test_sw_removed_stemmed['text']\n",
    "y_test = df_test_sw_removed_stemmed['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaee6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "65dd20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f185b8a",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "548e3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03045a86",
   "metadata": {},
   "source": [
    "**TF-IDF Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7eb60f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multinomial NB\n",
    "X_train_nb = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_nb = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7de2b3",
   "metadata": {},
   "source": [
    "**Multinomial NB Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ab9f2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB().fit(X_train_nb, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88576a58",
   "metadata": {},
   "source": [
    "**Multinomial NB Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e51c22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_pred = nb_model.predict(X_test_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "edbb23d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.13      0.22      5636\n",
      "        notr       0.98      0.89      0.94     17087\n",
      "    positive       0.79      0.99      0.88     26053\n",
      "\n",
      "    accuracy                           0.86     48776\n",
      "   macro avg       0.92      0.67      0.68     48776\n",
      "weighted avg       0.88      0.86      0.82     48776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nb_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae615c1",
   "metadata": {},
   "source": [
    "### Binary Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a3017372",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_binary = TfidfVectorizer(ngram_range=(1,2), binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e57425",
   "metadata": {},
   "source": [
    "**Binary TF-IDF Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e8affbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binary NB\n",
    "X_train_nb_binary = tfidf_vectorizer_binary.fit_transform(X_train)\n",
    "X_test_nb_binary = tfidf_vectorizer_binary.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07c2fa",
   "metadata": {},
   "source": [
    "**Binary NB Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6b0e70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_binary = BernoulliNB().fit(X_train_nb_binary, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ab00d",
   "metadata": {},
   "source": [
    "**Binary NB Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "13684c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_binary_model_pred = nb_model.predict(X_test_nb_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fc1f8187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.13      0.22      5636\n",
      "        notr       0.98      0.89      0.94     17087\n",
      "    positive       0.79      0.99      0.88     26053\n",
      "\n",
      "    accuracy                           0.86     48776\n",
      "   macro avg       0.92      0.67      0.68     48776\n",
      "weighted avg       0.88      0.86      0.82     48776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nb_binary_model_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
